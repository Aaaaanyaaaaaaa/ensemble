{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b26db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    http_client=httpx.Client(proxy=\"<YOUR PROXY>\"),  \n",
    "    api_key=\"<YOUR_KEY>\".encode('ascii', 'ignore').decode('ascii')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9668656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch import nn\n",
    "from torchvision import models, transforms, utils\n",
    "from torch.utils.data import DataLoader\n",
    "import torch, os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbee1f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "NUM_SECONDS_TO_SLEEP = 0.5\n",
    "\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "626f7096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e5dc3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e4d0631",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('<NAME>.json', 'r') as file: #original bboxes coordinates\n",
    "    orig_maira = json.load(file)\n",
    "\n",
    "with open('<NAME>.json', 'r') as file: #bboxes coordinates produced with MedRPG on step 1\n",
    "    medrpg = json.load(file)\n",
    "    \n",
    "with open('<NAME>.json', 'r') as file: #bboxes coordinates produced with Maira on step 2\n",
    "    maira = json.load(file)\n",
    "\n",
    "with open('<NAME>.json', 'r') as file:  #iou values for every picture produced with MedRPG on step 1\n",
    "    medrpg_iou = json.load(file)\n",
    "    \n",
    "with open('<NAME>.json', 'r') as file: #iou values for every picture produced with Maira on step 1\n",
    "    maira_iou = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae863e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_500 = pd.read_csv('gold_500.csv')\n",
    "body_parts = gold_500.bbox_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a423779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 373/373 [12:53<00:00,  2.07s/it]\n",
      "100%|██████████| 400/400 [15:11<00:00,  2.28s/it]\n",
      "100%|██████████| 16/16 [00:32<00:00,  2.01s/it]\n",
      "100%|██████████| 286/286 [09:29<00:00,  1.99s/it]\n",
      "100%|██████████| 404/404 [15:59<00:00,  2.37s/it]  \n",
      "100%|██████████| 283/283 [10:03<00:00,  2.13s/it]\n",
      "100%|██████████| 423/423 [14:21<00:00,  2.04s/it]\n",
      "100%|██████████| 412/412 [14:04<00:00,  2.05s/it]\n",
      "100%|██████████| 393/393 [13:58<00:00,  2.13s/it]\n",
      "100%|██████████| 488/488 [17:36<00:00,  2.16s/it]\n",
      "100%|██████████| 39/39 [01:18<00:00,  2.02s/it]\n",
      "100%|██████████| 463/463 [18:02<00:00,  2.34s/it]  \n",
      "100%|██████████| 443/443 [15:16<00:00,  2.07s/it]\n",
      "100%|██████████| 369/369 [13:26<00:00,  2.19s/it]\n",
      "100%|██████████| 369/369 [12:20<00:00,  2.01s/it]\n",
      "100%|██████████| 202/202 [06:51<00:00,  2.04s/it]\n",
      "100%|██████████| 360/360 [13:12<00:00,  2.20s/it]\n",
      "100%|██████████| 325/325 [17:38<00:00,  3.26s/it]   \n",
      "100%|██████████| 284/284 [09:57<00:00,  2.10s/it]\n",
      "100%|██████████| 489/489 [17:27<00:00,  2.14s/it]\n",
      "100%|██████████| 20/20 [00:37<00:00,  1.90s/it]\n",
      "100%|██████████| 481/481 [19:07<00:00,  2.38s/it]  \n",
      "100%|██████████| 423/423 [15:43<00:00,  2.23s/it]\n",
      "100%|██████████| 143/143 [05:23<00:00,  2.26s/it]\n",
      "100%|██████████| 8/8 [00:17<00:00,  2.19s/it]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "outliers = {}\n",
    "n_tries = 5\n",
    "iou_gpt = {}\n",
    "workers = {}\n",
    "\n",
    "\n",
    "for part in body_parts:\n",
    "\n",
    "    workers[part] =[]\n",
    "    iou_gpt[part] = []\n",
    "    \n",
    "    l = list(maira_iou[part].keys())\n",
    "    for image in tqdm(l):\n",
    "        \n",
    "        path = f\"with_gt_new/{part}/{image}\"  #link to the folder with images\n",
    "        if (os.path.exists(path)):\n",
    "            img_try = Image.open(path).convert(\"RGB\").resize((224, 224 ))\n",
    "\n",
    "            # blue -original\n",
    "            #red-maira\n",
    "            #yellow - medrpg\n",
    "\n",
    "    \n",
    "            promt2 = f\"You are given the image with three bounding boxes. The first bbox is red, the second bbox is blue, and the third is yellow. Please, analize the image and and tell what bbox describes the position of {part} better. Print Maira in case of the red bbox, MedRPG in case of the yellow bbox and Orig in case of the blue bbox.  Please, send ONLY one word\"\n",
    " \n",
    "\n",
    "            base64_image_1_224 = encode_image(path)\n",
    "\n",
    "            response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    messages=[\n",
    "                    {\n",
    "                      \"role\": \"user\",\n",
    "                      \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": promt2},\n",
    "                        {\n",
    "                          \"type\": \"image_url\",\n",
    "                          \"image_url\": {\n",
    "                              \"url\": f\"data:image/jpeg;base64,{base64_image_1_224}\",\n",
    "                          },\n",
    "                        },\n",
    "                      ],\n",
    "                    }\n",
    "                  ],\n",
    "                  max_tokens=300,\n",
    "                  )\n",
    "\n",
    "            response = response.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "            maira_gt_iou = maira_iou[part][image]\n",
    "            medrpg_gt_iou = medrpg_iou[part][image] \n",
    "            \n",
    "            \n",
    "            # in case chat gpt doesnot provide an answer accoring to the pattern we need to ask chat gpt again\n",
    "            if response.lower() not in [\"maira\", \"medrpg\", \"orig\"]:\n",
    "                for attempt in range(n_tries):\n",
    "                    r = client.chat.completions.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    messages=[\n",
    "                    {\n",
    "                      \"role\": \"user\",\n",
    "                      \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": promt2},\n",
    "                        {\n",
    "                          \"type\": \"image_url\",\n",
    "                          \"image_url\": {\n",
    "                                  \"url\": f\"data:image/jpeg;base64,{base64_image_1_224}\",\n",
    "                              },\n",
    "                            },\n",
    "                          ],\n",
    "                        }\n",
    "                      ],\n",
    "                      max_tokens=300,\n",
    "                      )\n",
    "                    r = r.choices[0].message.content\n",
    "                    if r.lower() in [\"maira\", \"medrpg\", \"orig\"]:\n",
    "                        response = r\n",
    "                        maira_gt_iou = maira_iou[part][image]\n",
    "                        medrpg_gt_iou = medrpg_iou[part][image]\n",
    "                        print(\"coorected response: \", r)\n",
    "                        break\n",
    "                    else:\n",
    "                        if part not in outliers.keys():\n",
    "                            #in case chatgpt still did not provide an answer we mark the picture as outlier\n",
    "                            outliers[part] = [path]\n",
    "                        else:\n",
    "                            outliers[part].append(path)\n",
    "                        maira_gt_iou = 0\n",
    "                        medrpg_gt_iou = 0\n",
    "                        print(\"incorrect response: \",r)\n",
    "\n",
    "                        \n",
    "                        \n",
    "            if response.lower() == \"maira\":\n",
    "                    iou_gpt[part].append(maira_gt_iou)\n",
    "                    \n",
    "            else:\n",
    "                if response.lower() == \"medrpg\":\n",
    "                    iou_gpt[part].append(medrpg_gt_iou) \n",
    "                   \n",
    "                else:     \n",
    "                    if response.lower() == \"orig\":\n",
    "                        iou_gpt[part].append(1) \n",
    "                        \n",
    "                    else:\n",
    "                        iou_gpt[part].append(0) \n",
    "                        \n",
    "            workers[part].append(response)\n",
    "            \n",
    "\n",
    "            with open('iou_with_gpt_v232323.json', 'w') as json_file:\n",
    "                json.dump(iou_gpt, json_file, allow_nan=True)\n",
    "\n",
    "            with open('workers_with_gpt_v232323.json', 'w') as json_file:\n",
    "                json.dump(workers, json_file, allow_nan=True)\n",
    "            with open('outliers_without_GT_232323.json', 'w') as json_file:\n",
    "                json.dump(outliers, json_file, allow_nan=True)\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_comparison",
   "language": "python",
   "name": "model_comparison"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
