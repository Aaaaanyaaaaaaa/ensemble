{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b9c771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    http_client=httpx.Client(proxy=\"<YOUR PROXY>\"),  \n",
    "    api_key=\"<YOUR_KEY>\".encode('ascii', 'ignore').decode('ascii')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c231e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch import nn\n",
    "from torchvision import models, transforms, utils\n",
    "from torch.utils.data import DataLoader\n",
    "import torch, os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29021f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "import time\n",
    "\n",
    "NUM_SECONDS_TO_SLEEP = 0.5\n",
    "\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3625309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c81df605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c77017ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('<NAME>.json', 'r') as file: #original bboxes coordinates\n",
    "    orig_maira = json.load(file)\n",
    "\n",
    "with open('<NAME>.json', 'r') as file: #bboxes coordinates produced with MedRPG on step 1\n",
    "    medrpg = json.load(file)\n",
    "    \n",
    "with open('<NAME>.json', 'r') as file: #bboxes coordinates produced with Maira on step 2\n",
    "    maira = json.load(file)\n",
    "\n",
    "with open('<NAME>.json', 'r') as file:  #iou values for every picture produced with MedRPG on step 1\n",
    "    medrpg_iou = json.load(file)\n",
    "    \n",
    "with open('<NAME>.json', 'r') as file: #iou values for every picture produced with Maira on step 1\n",
    "    maira_iou = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e7ff30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_500 = pd.read_csv('gold_500.csv')\n",
    "body_parts = gold_500.bbox_name.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8da15691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "confusion_matrix = {}\n",
    "#iou collecter\n",
    "iou_gpt ={}\n",
    "\n",
    "#collector of the predicted method\n",
    "workers = {}\n",
    "\n",
    "#images, that were not classified by chat gpt\n",
    "outliers = {}\n",
    "\n",
    "# number of tries\n",
    "n_tries = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33de6bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e524bb3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:42<00:00,  2.64s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for part in body_parts:\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    confusion_matrix[part] = []\n",
    "    iou_gpt[part] = []\n",
    "    workers[part] = []\n",
    "    \n",
    "    \n",
    "    l =  os.listdir(f\"without_gt_new/{part}\") # link to the folder with images\n",
    "    for image in tqdm(list(maira[part].keys())):\n",
    "        \n",
    "        path = f\"without_gt_new/{part}/{image}\"\n",
    "        if (os.path.exists(path)):\n",
    "            img_try = Image.open(path).convert(\"RGB\").resize((224, 224))\n",
    "\n",
    "\n",
    "            promt2 = f\"You are given the image with two bounding boxes. The first bbox is red, the second bbox is yellow. Please, analize the image and and tell what bbox describes the position of {part} better. Print Maira in case of the red bbox, MedRPG in case of the yellow bbox.  Please, send ONLY one word\"\n",
    "\n",
    "            base64_image_1_224 = encode_image(path)\n",
    "\n",
    "            response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    messages=[\n",
    "                    {\n",
    "                      \"role\": \"user\",\n",
    "                      \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": promt2},\n",
    "                        {\n",
    "                          \"type\": \"image_url\",\n",
    "                          \"image_url\": {\n",
    "                              \"url\": f\"data:image/jpeg;base64,{base64_image_1_224}\",\n",
    "                          },\n",
    "                        },\n",
    "                      ],\n",
    "                    }\n",
    "                  ],\n",
    "                  max_tokens=300,\n",
    "                  )\n",
    "\n",
    "            response = response.choices[0].message.content\n",
    "            \n",
    "            maira_gt_iou = maira_iou[part][image]\n",
    "            medrpg_gt_iou = medrpg_iou[part][image]\n",
    "            \n",
    "            \n",
    "            # in case chat gpt doesnot provide an answer accoring to the pattern we need to ask chat gpt again\n",
    "            if response.lower() not in [\"maira\", \"medrpg\"]:\n",
    "                for attempt in range(n_tries):\n",
    "                    r = client.chat.completions.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    messages=[\n",
    "                    {\n",
    "                      \"role\": \"user\",\n",
    "                      \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": promt2},\n",
    "                        {\n",
    "                          \"type\": \"image_url\",\n",
    "                          \"image_url\": {\n",
    "                                  \"url\": f\"data:image/jpeg;base64,{base64_image_1_224}\",\n",
    "                              },\n",
    "                            },\n",
    "                          ],\n",
    "                        }\n",
    "                      ],\n",
    "                      max_tokens=300,\n",
    "                      )\n",
    "                    r = r.choices[0].message.content\n",
    "                    if r.lower() in [\"maira\", \"medrpg\"]:\n",
    "                        response = r\n",
    "                        maira_gt_iou = maira_iou[part][image]\n",
    "                        medrpg_gt_iou = medrpg_iou[part][image]\n",
    "                        print(\"coorected response: \", r)\n",
    "                        break\n",
    "                    else:\n",
    "                        if part not in outliers.keys():\n",
    "                            #in case chatgpt still did not provide an answer we mark the picture as outlier\n",
    "                            outliers[part] = [path]\n",
    "                        else:\n",
    "                            outliers[part].append(path)\n",
    "                        maira_gt_iou = 0\n",
    "                        medrpg_gt_iou = 0\n",
    "                        print(\"incorrect response: \",r)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if response.lower() == \"maira\":\n",
    "                    iou_gpt[part].append(maira_gt_iou)\n",
    "            else:\n",
    "                if response.lower() == \"medrpg\":\n",
    "                    iou_gpt[part].append(medrpg_gt_iou) \n",
    "                else:\n",
    "                    iou_gpt[part].append(0) \n",
    "            workers[part].append(response.lower())\n",
    "\n",
    "\n",
    "            if response.lower() == \"maira\":\n",
    "                    if maira_gt_iou>medrpg_gt_iou:\n",
    "                        TP += 1\n",
    "                    if maira_gt_iou<=medrpg_gt_iou:   \n",
    "                        FP +=1\n",
    "            else :\n",
    "                if response.lower() == \"medrpg\":\n",
    "                    if maira_gt_iou>=medrpg_gt_iou:\n",
    "                        FN += 1\n",
    "                    if maira_gt_iou<medrpg_gt_iou: \n",
    "                        TN +=1\n",
    "\n",
    "            confusion_matrix[part] = (TP, FP, TN, FN )\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "            \n",
    "\n",
    "        with open('<CONFUSION MATRIX FILE NAME>.json', 'w') as json_file:\n",
    "            json.dump(confusion_matrix, json_file, allow_nan=True)\n",
    "        with open('<IOU FILE NAME>.json', 'w') as json_file:\n",
    "            json.dump(iou_gpt, json_file, allow_nan=True)\n",
    "        with open('<WORKERS FILE NAME>.json', 'w') as json_file:\n",
    "            json.dump(workers, json_file, allow_nan=True)\n",
    "        with open('<OUTLIERS FILE NAME>.json', 'w') as json_file:\n",
    "            json.dump(outliers, json_file, allow_nan=True)\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf84250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110e5307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9501ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d79824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7711851",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_comparison",
   "language": "python",
   "name": "model_comparison"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
